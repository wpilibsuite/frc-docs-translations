# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2021, FIRST and other WPILib Contributors
# This file is distributed under the same license as the FIRST Robotics Competition package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
# 
# Translators:
# Andre Theberge <atheberge2@videotron.ca>, 2021
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: FIRST Robotics Competition 2021\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-06-27 16:03+0000\n"
"PO-Revision-Date: 2021-06-22 22:09+0000\n"
"Last-Translator: Andre Theberge <atheberge2@videotron.ca>, 2021\n"
"Language-Team: French (Canada) (https://www.transifex.com/wpilib/teams/109324/fr_CA/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: fr_CA\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:2
msgid "Introduction to Machine Learning"
msgstr "Introduction à l'apprentissage automatique"

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:4
msgid ""
"Machine learning is a giant optimization problem. A neural network is a "
"series of matrices, where the number contained within the matrices need to "
"be tuned as precisely as possible to make the best predictions possible. To "
"understand what this means better, let's look at a classic machine learning "
"problem: MNIST."
msgstr ""
"L'apprentissage automatique est un problème d'optimisation énorme. Un réseau"
" de neurones est une série de matrices, où le nombre contenu dans les "
"matrices doit être réglé de façon très précise pour faire les meilleures "
"prédictions possibles. Pour mieux comprendre ce que cela signifie, examinons"
" un problème classique d'apprentissage automatique: MNIST."

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:7
msgid "MNIST"
msgstr "MNIST"

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:12
msgid ""
"MNIST (\"Modified National Institute of Standards and Technology\") is a "
"commonly used datatset in Computer Vision that deals with classification. "
"The dataset itself is a collection of images showing hand-drawn numbers. The"
" challenge is to create an algorithm that can recognize what number is "
"represented by a given image, which is solvable by developing a neural "
"network."
msgstr ""
"Le MNIST (« Institut national modifié des normes et de la technologie ») est"
" un ensemble de données couramment utilisé en vision par ordinateur qui "
"traite de la classification. L'ensemble de données lui-même est une "
"collection d'images montrant des nombres dessinés à la main. Le défi "
"consiste à créer un algorithme capable de reconnaître quel nombre est "
"représenté par une image donnée, ce qui peut être résolu en développant un "
"réseau de neurones."

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:17
msgid ""
"Here we have an over-simplified neural network. It has three layers, "
"arranged vertically. The furthest left layer is called the input layer. When"
" feeding an image into the neural network, the input layer is set to have "
"the same values as our image. The middle layer is called a hidden layer. "
"This layer focuses on computation, and does not directly interact with by "
"the programmer. The final layer in this neural network is called the output "
"layer and contains the end result."
msgstr ""
"Ici, nous avons un réseau de neurones trop simplifié. Il a trois couches, "
"disposées verticalement. La couche la plus à gauche est appelée couche "
"d'entrée. Lors de l'alimentation d'une image dans le réseau de neurones, la "
"couche d'entrée est définie pour avoir les mêmes valeurs que notre image. La"
" couche intermédiaire est appelée couche cachée. Cette couche se concentre "
"sur le calcul et n'interagit pas directement avec le programmeur. La couche "
"finale de ce réseau de neurones est appelée couche de sortie et contient le "
"résultat final."

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:19
msgid ""
"Having discussed the nodes (the circles) that make up the layers, it is "
"important to discuss the connections (the arrows) between the layers. Each "
"arrow represents a set of operations between two nodes. This type of neural "
"network is a fully-connected neural network, so the operations that the "
"arrows represent are shown below."
msgstr ""
"Après avoir présenté les nœuds (les cercles) qui composent les couches, il "
"est important de discuter des connexions (les flèches) entre les couches. "
"Chaque flèche représente un ensemble d'opérations entre deux nœuds. Ce type "
"de réseau de neurones est un réseau de neurones entièrement connecté, les "
"opérations représentées par les flèches sont donc indiquées ci-dessous."

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:21
msgid ""
"Y = WX + b\n"
"\n"
msgstr ""
"Y = WX + b\n"
"\n"

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:23
msgid ""
"Where :math:`Y` is a non-input matrix layer, and :math:`X` is the matrix "
"directly before (to the left) of :math:`Y`. :math:`W` is a matrix of weights"
" that act as coefficients on :math:`X`. :math:`b` is a matrix of biases that"
" add to the result of the product of :math:`W` and :math:`X`. During the "
"training/learning process, the values within :math:`W` and :math:`b` are "
"adjusted so :math:`Y` is the best possible value from any :math:`X`. In a "
"large neural network, there are millions of weights and biases, resulting in"
" billions of linear algebra operations. This absurd amount math often "
"requires a powerful computer, and/or a lot of time."
msgstr ""
"Où :math:`Y` est une couche matricielle sans entrée, et :math:`X` est la "
"matrice juste avant (à gauche) de :math:`Y`. :math:`W` est une matrice de "
"poids qui agissent comme des coefficients sur :math:`X`. :math:`b` est une "
"matrice de biais qui s'ajoutent au résultat du produit de :math:`W` et "
":math:`X`. Pendant le processus de formation/apprentissage, les valeurs "
"entre :math:`W` et :math:`b` sont ajustées de sorte que :math:`Y` soit la "
"meilleure valeur possible parmi tous les :math:`X`. Dans un grand réseau de "
"neurones, il existe des millions de poids et de biais, ce qui entraîne des "
"milliards d'opérations d'algèbre linéaire. Ce calcul démentiel nécessite "
"souvent un ordinateur puissant et/ou beaucoup de temps."

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:25
msgid ""
"With this understanding of a basic neural network, let's look at a simple "
"neural network that can be used for the MNIST problem."
msgstr ""
"Avec cette compréhension d'un réseau de neurones de base, examinons un "
"réseau de neurones simple qui peut être utilisé pour le problème MNIST."

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:30
msgid ""
"This neural network has an input layer, one hidden layer, and an output "
"layer. The input layer is made of 784 nodes, as the MNIST dataset is made "
"out of pictures that are 28x28 pixels. Each pixel is either 0 or 1. This "
"input layer is multiplied by a weights matrix and a bias matrix is added, "
"resulting in the hidden layer. The hidden layer is multiplied by another "
"weight matrix and another bias matrix is added, resulting in the output "
"layer. The output layer is made of exactly 10 nodes, representing 0 through "
"9. The actual value of each node represents the confidence of that node "
"being correct. For example, if node 0 has a value of .91, and node 1 has a "
"value of .23, then the input image is more likely a 0 than a 1."
msgstr ""
"Ce réseau de neurones a une couche d'entrée, une couche cachée et une couche"
" de sortie. La couche d'entrée est composée de 784 nœuds, car le jeu de "
"données MNIST est composé d'images de 28x28 pixels. Chaque pixel est soit 0,"
" soit 1. Cette couche d'entrée est multipliée par une matrice de pondération"
" et une matrice de biais est ajoutée, ce qui donne la couche cachée. La "
"couche cachée est multipliée par une autre matrice de poids et une autre "
"matrice de biais est ajoutée, ce qui donne la couche de sortie. La couche de"
" sortie est composée d'exactement 10 nœuds, représentant 0 à 9. La valeur "
"réelle de chaque nœud représente la confiance de ce nœud étant correct. Par "
"exemple, si le nœud 0 a une valeur de 0,91 et que le nœud 1 a une valeur de "
"0,23, alors l'image d'entrée est plus probablement un 0 qu'un 1."

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:33
msgid "MobileNet V2"
msgstr "MobileNet V2"

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:35
msgid ""
"The neural network that Axon uses is much more complex than the one "
"described for the MNIST problem. It is a convolutional neural network (CNN),"
" distinctly different than the fully-connected neural network used for "
"MNIST."
msgstr ""
"Le réseau de neurones utilisé par Axon est beaucoup plus complexe que celui "
"décrit pour le problème MNIST. Il s'agit d'un réseau neuronal convolutif "
"(CNN), nettement différent du réseau neuronal entièrement connecté utilisé "
"pour le MNIST."

#: ../../frc-docs/source/docs/software/wpilib-tools/axon/machine-learning.rst:40
msgid ""
"If you would like to learn more about the MobileNet architecture, you can "
"read `here. <https://arxiv.org/abs/1704.04861>`__ This knowledge is not "
"necessary to use Axon to successfully deploy a neural network on your robot."
msgstr ""
"Si vous souhaitez en savoir plus sur l'architecture MobileNet, vous pouvez "
"lire `ici. <https://arxiv.org/abs/1704.04861>`__ Cette connaissance n'est "
"pas nécessaire pour utiliser Axon pour déployer avec succès un réseau de "
"neurones sur votre robot."
